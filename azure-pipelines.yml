# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

# Takes the variables from the Databricks-environment group defined in the Library tab.
variables:
- group: Databricks-environment

trigger:
- master

pool:
  vmImage: 'ubuntu-latest'

steps:
- task: UsePythonVersion@0
  displayName: 'Use Python 3.7'
  inputs:
    versionSpec: 3.7

# Install required Python modules, including databricks-connect, required to execute a unit test
# on a cluster.
- script: |
    pip install pytest requests setuptools wheel
    pip install -U databricks-connect==6.4.*
  displayName: 'Load Python Dependencies'

# Use environment variables to pass Databricks login information to the Databricks Connect
# configuration function
- script: |
    echo "y
    $(WORKSPACE-REGION-URL)
    $(TOKEN)
    $(EXISTING-CLUSTER-ID)
    $(WORKSPACE-ORG-ID)
    15001" | databricks-connect configure
  displayName: 'Configure DBConnect'

#Get the latest changes: downloads code from the designated branch to the agent execution agent.
- checkout: self
  persistCredentials: true
  clean: true

- script: git checkout master
  displayName: 'Get Latest Branch'

#Invoke the unit tests, specifying the name and location for both the tests and the output files
- script: |
    python -m pytest --junit-xml=$(Build.Repository.LocalPath)/logs/TEST-LOCAL.xml $(Build.Repository.LocalPath)/test_*.py || true
    ls logs
  displayName: 'Run Python Unit Tests for library code'

#After all unit tests have been executed, publish the results to Azure DevOps. 
#This lets you visualize reports and dashboards related to the status of the build process.
- task: PublishTestResults@2
  inputs:
    testResultsFiles: '**/TEST-*.xml'
    failTaskOnFailedTests: true
    publishRunAttachments: true
